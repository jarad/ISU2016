\documentclass[handout,10pt]{beamer}

\usetheme{AnnArbor}
\usecolortheme{beaver}

\graphicspath{{include/}}

\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}

\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{enumerate items}[default]
\setbeamertemplate{enumerate subitem}{\alph{enumii}.}
\setbeamertemplate{enumerate subsubitem}{\roman{enumiii}.}
\setkeys{Gin}{width=0.6\textwidth}

\newcommand{\ind}{\stackrel{ind}{\sim}}
\providecommand{\ov}[1]{\overline{#1}}


\institute[ISU]{Iowa State University}
\date{\today}

\title[Fully Bayes RNAseq analysis]{Fully Bayesian analysis of RNAseq data for gene expression heterosis detection}
\author{Dr. Jarad Niemi}

\begin{document}



\begin{frame}
\maketitle

\pause

{\small
Dr. Dan Nettleton, Dr. Will Landau, Eric Mittman, and Ignacio Alvarez-Castro
}

\vspace{0.2in} \pause

{\tiny
This research was supported by National Institute of General Medical Sciences (NIGMS) of the National Institutes of Health and the joint National Science Foundation / NIGMS Mathematical Biology Program under award number R01GM109458. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health or the National Science Foundation.
}

\end{frame}



\begin{frame}
\frametitle{Outline}

\begin{itemize}
\item Background
	\begin{itemize}
	\item Heterosis
	\item RNAseq data \pause
	\end{itemize}
\item Modeling 
	\begin{itemize}
	\item Composite null hypothesis \pause
	\item Hierarchical overdispersed count regression model
	\end{itemize}
\item Inference
	\begin{itemize}
	\item Empirical Bayes
	\item Fully Bayes \pause on graphics processing units
		\begin{itemize}
		\item Memory transfers
		\item Random number generation \pause
		\end{itemize}
	\end{itemize}
\item Simulation studies
	\begin{itemize}
	\item Credible interval coverage
	\item Heterosis detection via ROC curves \pause
	\end{itemize}
\item Real data analysis \pause
\item Future work
\end{itemize}

\end{frame}


\section{Background}
\subsection{Heterosis}

\begin{frame}
\frametitle{Heterosis}
\begin{definition}
Heterosis, or hybrid vigor, is the enhancement of the phenotype of hybrid progeny relative to their inbred parents.
\end{definition}

\pause

\begin{center}
\includegraphics{heterosis}
\end{center}
{\tiny (\url{http://www2.iastate.edu/~nscentral/news/06/may/vigor.shtml} modified by Will Landau)} 
\end{frame}



\subsection{RNAseq data}
% \begin{frame}
% \frametitle{RNAseq data}
% \setkeys{Gin}{width=0.8\textwidth}
% \begin{center}
% \includegraphics{rnaseq}
% \end{center}
% {\tiny Wang, Gerstein, and Snyder. (2010) \url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2949280/figure/F1/}}
% \end{frame}


% \begin{frame}
% \frametitle{RNAseq data}
% \begin{center}
% \includegraphics{rnaseq2}
% \end{center}
% {\tiny url{http://bio.lundberg.gu.se/courses/vt13/rnaseq.html}}
% \end{frame}


\begin{frame}
\frametitle{RNA fragmentation, sequencing, and alignment}
\setkeys{Gin}{width=0.5\textwidth}
\begin{center}
\includegraphics{rnaseq3}
\end{center}
{\tiny (Pepke, Wold, and Mortazavi (2009) \url{http://www.nature.com/nmeth/journal/v6/n11s/fig_tab/nmeth.1371_F5.html})}
\end{frame}



\begin{frame}
\frametitle{RNAseq data}
\setkeys{Gin}{width=0.8\textwidth}

\begin{center}
\includegraphics{data}
\end{center}
{\tiny (Will Landau)}

\end{frame}


\section{Modeling}
\subsection{Composite null hypothesis}
\begin{frame}
\frametitle{Hypotheses}
\setkeys{Gin}{width=0.2\textwidth}
\footnotesize

For a given gene, let 
\begin{itemize}\scriptsize
\item $\mu_{B\phantom{M}}$: mean expression for B73 inbred parent,
\item $\mu_{M\phantom{B}}$: mean expression for Mo17 inbred parent,
\item $\mu_{BM}$: mean expression for B73$\times$Mo17 F1 hybrid, and
\item $\mu_{MB}$: mean expression for Mo17$\times$B73 F1 hybrid.
\end{itemize}
\pause
We are interested in comparing hypotheses of the form
\[ 
H_0: \mu_{min} < \mu_{BM} < \mu_{max}, \qquad H_{LPH}: \mu_{BM} < \mu_{min}, \qquad H_{HPH}: \mu_{max} < \mu_{BM}
\]
where $\mu_{min} = \min(\mu_B,\mu_M)$ and $\mu_{max} = \max(\mu_B,\mu_M)$. 

\vspace{0.1in} \pause

<<echo=FALSE, out.width='0.3\\textwidth', fig.align='center', fig.width=4, fig.height=4>>=
mB = expression(mu[B])
mM = expression(mu[M])
mBM = expression(mu[BM])

opar = par(mar=rep(0,4)+.1)
plot(0,0, type="n", axes=FALSE, xlab="", ylab="", xlim=c(-1,1), ylim=c(-1,1))
polygon(c(0,-2,-2,0), c(0,2,-2,0), col='pink', border=NA)
polygon(c(0, 2, 2,0), c(0,2,-2,0), col='pink', border=NA)
abline(0, 1)
abline(0,-1)
abline(0,0,lty=2)
text(-0.8, 1, expression(mu[B]==mu[BM]))
text( 0.8, 1, expression(mu[BM]==mu[M]))
text( 0.9,.05, expression(mu[B]==mu[M]))
text( 0.0, 0.8, expression(paste(mu[B], "<", mu[BM] < mu[M])))
text( 0.8, 0.5, expression(paste(mu[B], "<", mu[M] < mu[BM])))
text( 0.8,-0.5, expression(paste(mu[M], "<", mu[B] < mu[BM])))
text( 0.0,-0.8, expression(paste(mu[M], "<", mu[BM] < mu[B])))
text(-0.8,-0.5, expression(paste(mu[BM], "<", mu[M] < mu[BM])))
text(-0.8, 0.5, expression(paste(mu[BM], "<", mu[B] < mu[M])))
text(-0.5, 0, "LPH", cex=2)
text( 0.5, 0, "HPH", cex=2)
par(opar)
@
\end{frame}



\begin{frame}
\frametitle{Posterior hypothesis probabilities}
\small

If we had a posterior distribution for the mean expression levels, i.e. 
\[ 
p(\mu_B,\mu_M,\mu_{BM},\mu_{MB}|y)
\]
where $y$ represents our data, 
then we could calculate the relevant hypothesis probabilities, i.e. 
\[ \begin{array}{rl}
P(H_{0\phantom{PH}}|y) &= P(\mu_{min} < \mu_{BM} < \mu_{max}|y) \\
P(H_{LPH}|y) &= P(\mu_{BM} < \mu_{min}|y) \\
P(H_{HPH}|y) &= P(\mu_{max} < \mu_{BM}|y)
\end{array} \]
where $\mu_{min} = \min(\mu_B,\mu_M)$ and $\mu_{max} = \max(\mu_B,\mu_M)$. 

\vspace{0.1in} \pause

Hierarchical modeling \emph{partially pools} the information across genes and thereby provides a data-based multiple comparison adjustment by 
\begin{itemize}
\item shrinking estimates toward a grand mean (or zero) based on the variability inherent in the data and 
\item reducing posterior uncertainty by borrowing information across genes. 
\end{itemize}
{\tiny (Gelman, Hill, and Yajima (2012))}

\end{frame}


\subsection{Hierarchical overdispersed count regression model}
\begin{frame}
\frametitle{Overdispersed count regression model}

Let 
\begin{itemize}
\item $g$ ($g=1,\ldots,G$) identify the gene, 
\item $n$ ($n=1,\ldots,N$) identify the sample, \pause
\item $y$ be the $G\times N$ matrix of RNAseq counts \pause and
\item $X$ be the $N\times L$ model matrix that connects the $N$ samples to the varieties, blocking factors, etc.
\end{itemize}
We assume 
\[ 
y_{gn} \ind \text{Po} \left (e^{h_n + \varepsilon_{gn} + x_n' \beta_{g}} \right )
\]
where 
\begin{itemize}
\item $h_n$ are \emph{normalization factors},
\item $\varepsilon_{gn} \ind N(0,\gamma_g)$ allow for gene-specific overdispersion, 
\item $x_n$ is the $n^{th}$ row of $X$, and
\item $\beta_g$ is a vector of length $L$ that account for effects on gene expression of variables of interest. 
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Hierarchical model}

Recall 
\[ 
y_{gn} \ind \text{Po} \left (e^{h_n + \varepsilon_{gn} + x_n' \beta_{g}} \right )
\qquad\mbox{and}\qquad
\varepsilon_{gn} \ind N(0,\gamma_g).
\]

\vspace{0.1in} \pause

We construct a hierarchical model for both $\gamma_g$ and $\beta_g$ to borrow information across genes. \pause
Specifically, we assume
\[ 
1/\gamma_g\ind \text{Ga} \left (\nu/2,\nu\tau/2 \right)
\]
such that $E[1/\gamma_g] = 1/\tau$ and $CoV[1/\gamma_g] = \sqrt{2/\nu}$ \pause and 
\[ 
\beta_{g\ell} \ind N(\theta_\ell, \sigma_\ell^2)
\]
for $\ell=1,\ldots,L$. 
\end{frame}



\begin{frame}
\frametitle{Model matrix for our heterosis experiment}

Experimental design:  4 varieties, 2 plates, 2 replicates per variety per plate

\pause

\begin{equation*} 
X = \left (
\begin{bmatrix}
1 & \phantom{-}1 & -1 & \phantom{-}0 \\
1 & -1 & \phantom{-}1 & \phantom{-}0 \\
1 & \phantom{-}1 & \phantom{-}1 & \phantom{-}1 \\
1 & \phantom{-}1 & \phantom{-}1 & -1 \\
\end{bmatrix} \otimes J_{(N/4) \times 1} \qquad \qquad
J_{(N/4) \times 1} \otimes
\begin{bmatrix}
\phantom{-}1  \\
\phantom{-}1  \\
-1 \\
-1  \\
\end{bmatrix} \right )
\end{equation*}
where $\otimes$ denotes the Kronecker product and $J_{m \times n}$ is the $m$ by $n$ matrix with all entries equal to 1.

\vspace{0.1in} \pause

Interpretations of the gene-specific parameters (dropping the $g$ subscript) are
\begin{itemize}
\item $\beta_1$ is the parental mean
\item $\beta_2$ is the half difference of hybrid mean vs M
\item $\beta_3$ is the half difference of hybrid mean vs B
\item $\beta_4$ is the half difference between hybrid
\item $\beta_5$ is the flow cell block effect 
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Heterosis hypotheses}

{\footnotesize
\begin{tabular}{l|l|l}
Heterosis & With log-scale group means  & With $\beta_{g\ell}$ parameters \\ \hline
high-parent BM & $\phantom{1\mu_{g,\text{BM}} + } \mu_{g,\text{BM}} > \phantom{2} \max \left (\mu_{g,\text{B}}, \mu_{g,\text{M}} \right )$ & $\phantom{-}2\beta_{g2} + \beta_{g4}, \phantom{-}2\beta_{g3} + \beta_{g4} > 0$ \\
low-parent BM & $\phantom{1\mu_{g,\text{BM}} + }\mu_{g,\text{BM}} < \phantom{2}  \min\, \left (\mu_{g,\text{B}}, \mu_{g,\text{M}} \right )$ & $-2\beta_{g2} - \beta_{g4}, -2\beta_{g3} - \beta_{g4} > 0$ \\
high-parent MB & $\phantom{1\mu_{g,\text{BM}} + }\mu_{g,\text{MB}} > \phantom{2}  \max \left (\mu_{g,\text{B}}, \mu_{g,\text{M}} \right )$ & $\phantom{-}2\beta_{g2} - \beta_{g4}, \phantom{-}2\beta_{g3} - \beta_{g4} > 0$ \\
low-parent MB & $\phantom{1\mu_{g,\text{BM}} + }  \mu_{g,\text{MB}} < \phantom{2} \min\, \left (\mu_{g,\text{B}}, \mu_{g,\text{M}} \right )$ & $-2\beta_{g2} + \beta_{g4}, \phantom{-}2\beta_{g3} + \beta_{g4} > 0$ \\
high-parent mean & $\mu_{g,\text{BM}} + \mu_{g,\text{MB}} > 2 \max \left (\mu_{g,\text{B}}, \mu_{g,\text{M}} \right )$ & $\phantom{-}\beta_{g2}, \phantom{-}\beta_{g3} > 0$ \\
low-parent mean & $\mu_{g,\text{BM}} + \mu_{g,\text{MB}} < 2 \min\, \left (\mu_{g,\text{B}}, \mu_{g,\text{M}} \right )$ & $-\beta_{g2}, -\beta_{g3} > 0$ 
\end{tabular}
}

\vspace{0.2in} \pause

All hypothesis regions are intersections of contrast events\pause, but we can also accomodate unions of contrast events via 
\[ 
P(A\cup B) = P(A) + P(B) - P(A \cap B).
\]

\end{frame}

\begin{frame}
\frametitle{Directed acyclic graphical model}
\setkeys{Gin}{width=\textwidth}

\vspace{-0.1in}

\begin{center}
\begin{minipage}{0.49\textwidth}
\includegraphics{dag3c}
\end{minipage}
\begin{minipage}{0.49\textwidth}
\[ \begin{array}{l}
p(\varepsilon,\beta,\gamma,\theta,\sigma,\tau,\mu|y) = \\ \\
p(\varepsilon,\beta,\gamma|\tau,\nu,\theta,\sigma, y) \\
\, \times p(\tau,\nu,\theta,\sigma|y) \propto \\ \\
\quad \prod_{g=1}^G \left\{ \left[ \prod_{n=1}^N p(y_{gn}|\beta_{g},\varepsilon_{gn}) p(\varepsilon_{gn}|\gamma_g) \right] \right. \\
\quad \phantom{\prod_{g=1}^G} \left[\prod_{\ell=1}^L p(\beta_{g\ell}|\theta_\ell,\sigma_\ell) p(\theta_\ell) p(\sigma_\ell) \right] \\
\quad \left.\phantom{\prod_{g=1}^G} p(\gamma_g|\tau,\nu) \right\} p(\tau)p(\nu)
\end{array} \]
\end{minipage}
{\tiny (Will Landau)}
\end{center}

% \begin{figure}[htbp]
%    \centering
%    \begin{minipage}{0.49\textwidth}
%    \begin{align*}
% &y_{gn} \stackrel{\text{ind}}{\sim} \text{Poisson} \left (\exp \left (h_n + \varepsilon_{gn} + X_n \beta_{g} \right ) \right ) \\
% & \qquad \varepsilon_{gn} \stackrel{\text{ind}}{\sim} \text{Normal}(0, \gamma_g) \\
% & \qquad \qquad \gamma_g \stackrel{\text{ind}}{\sim} \text{Inverse-Gamma}\left (\frac{\nu}{2}, \frac{\nu \tau}{2} \right) \\
% & \qquad \qquad \qquad \nu \stackrel{\text{}}{\sim} \text{Uniform}(0, d) \\
% & \qquad \qquad \qquad \tau \stackrel{\text{}}{\sim} \text{Gamma}(a, \text{rate} = b) \\
% & \qquad \beta_{g\ell} \stackrel{\text{ind}}{\sim} \text{Normal}(\theta_\ell, \sigma_\ell^2) \\
% & \qquad \qquad \theta_\ell \stackrel{\text{ind}}{\sim} \text{Normal}(0, c_\ell^2) \\
% & \qquad \qquad \sigma_\ell \stackrel{\text{ind}}{\sim} \text{Uniform}(0, s_\ell)
% \end{align*}
%    \end{minipage} 
%    \begin{minipage}{0.49\textwidth}
%    \includegraphics{dag3c}
%    \end{minipage}
% \end{figure}

where $G\approx 40\,000$, $N=16$, and $L=5$ in our application \pause and thus we have 
\begin{itemize}
\item $G\times N + G + 2 + G\times L + 2\times L \approx 800\,000$ parameters \pause
\item and $G\times N \approx 640\,000$ observations.
\end{itemize}
\end{frame}




\section{Inference}
\subsection{Empirical Bayes}
\begin{frame}[fragile]
\frametitle{Empirical Bayes}
\small

First we tried to fit this model using black-box Bayesian software, i.e. JAGS and Stan, but it appears computationally intractable using these platforms. 

\vspace{0.2in} \pause

Niemi, Mittman, Landau, and Nettleton (2015) used an empirical Bayes approach by 
{\footnotesize
\begin{enumerate}
\item using moment matching techniques on independent gene-specific parameter estimates to obtain hyperparameter estimates
\item and then parallelizing the MCMC across genes, i.e. 
\end{enumerate}
\[
p(\varepsilon,\beta,\gamma|\hat{\tau},\hat{\nu},\hat{\theta},\hat{\sigma}, y) \propto
\prod_{g=1}^G \left\{ \left[ \prod_{n=1}^N p(y_{gn}|\beta_{g},\varepsilon_{gn}) p(\varepsilon_{gn}|\gamma_g) \right] \left[\prod_{\ell=1}^L p(\beta_{g\ell}|\hat\theta_\ell,\hat\sigma_\ell) \right]
p(\gamma_g|\hat\tau,\hat\nu) \right\}
\]

}

\pause

<<eval=FALSE, size="tiny">>=
if (require(doMC)) {
  registerDoMC()
} else {
  parallel=FALSE
}

analysis = adply(d,
                 1,
                 function(x) single_gene_analysis(x),
                 .id = 'gene',
                 .parallel = parallel,
                 .paropts = list(.export=c('single_gene_analysis','model','hyperparameters'), .packages='rstan'))
@

\pause

Took about 10 hours to run. 

\end{frame}





\subsection{Fully Bayes}
\begin{frame}
\frametitle{Priors}

All priors are constructed to be vague, proper, and (if possible) conditionally conjugate. \pause 
There are $2(L+1)$ hyperparameters and we assign the following priors
\[ \begin{array}{rll}
\tau &\sim Ga(a,b) & \mbox{conditionally conjugate} \\
\nu &\sim Unif(0,d) \\
\theta_\ell &\ind N(0,c_\ell^2) & \mbox{conditionally conjugate} \\
\sigma_\ell &\ind Unif(0,s_\ell) & \mbox{Gelman (2006)}
\end{array} \]
\pause
As we'll see, posterior distributions for these parameters are extremely tight relative to their priors. 

\end{frame}





\begin{frame}
\frametitle{Constructing a Gibbs sampler}

Conditional independence within a step:
\[ \begin{array}{rl}
p(\varepsilon|\ldots) &\propto \prod_{g=1}^G \prod_{n=1}^N Po\left(y_{gn}|e^{h_n+\varepsilon_{gn}+x_n'\beta_g}\right)N(\varepsilon_{gn}|0,\gamma_g) \\
p(\gamma|\ldots) &\propto \prod_{g=1}^G \prod_{n=1}^N N(\varepsilon_{gn}|0,\gamma_g) IG(\gamma_g,\nu/2,\nu\tau/2) \\
p(\beta_{\ell}|\ldots) &\propto \prod_{g=1}^G \prod_{n=1}^N Po\left(y_{gn}|e^{h_n+\varepsilon_{gn}+x_n'\beta_g}\right)N(\beta_{g\ell}|\theta_\ell, \sigma_\ell^2) 
\end{array} \]

\vspace{0.1in} \pause

Sufficient ``statistics'':
\[ \begin{array}{rl@{\qquad}rl}
p(\tau|\ldots) &\sim Ga(\tau|a',b') & (a',b') &= f_{\tau}(\gamma,\nu,a,b) \\
p(\nu|\ldots) &\sim p(\mu|d')\mathrm{I}(0<\nu<d) & d' &= f_\nu(\gamma,\tau,d) \\
p(\theta_\ell|\ldots) &\sim N(\theta_\ell|m'_\ell, C'_\ell) & (m'_\ell,C'_\ell) &= f_{\theta_\ell}(\beta_\ell,\sigma_\ell,c_\ell^2) \\
p(\sigma_\ell^2|\ldots) &\sim IG(e',f') \mathrm{I}(0<\sigma_\ell^2<s^2_\ell) & (e',f') &= f_{\sigma_\ell}(\beta_\ell,\theta_{\ell})
\end{array} \]
\pause
where the functions calculate means, variances, products, etc. over $G$ terms. 
\end{frame}


\subsection{GPUs}
\begin{frame}
\frametitle{Parallel hardware platforms}

(All values are orders of magnitude)

\begin{center}
\begin{tabular}{l|rrr}
& \multicolumn{3}{c}{Platform} \\
& Multicore & Accelerator (GPU) & Cluster \\
\hline
\# of nodes &  10 &  1000 &  100+ \\
node speed (GHz) &  1 &  1/2 &  1   \\
memory (GB) &  10 &  10 &  10/node \\
node comm. speed (GB/s) &  10 &  10 &  1 \\
data transfer speed (GB/s) & N/A &  1 &  1 \\
\hline
\end{tabular}
\end{center}

\vspace{0.1in} \pause

The combination of 
\begin{itemize}
\item number of nodes and
\item node communication speed
\end{itemize}
make accelerators a good choice for parallelizable MCMC.

\end{frame}


\begin{frame}
\frametitle{Parallization translated to a GPU}

If there are $G$ nodes, then 
\begin{itemize}
\item Conditional inpdendence $\to$ embarrassingly parallel - possible speedup is $G$
\item Calculate sufficient ``statistics'' $\to$ reduction - possible speedup is $[G-1]/\log_2(G)$
\end{itemize}

\vspace{0.1in} \pause

\begin{center}
\includegraphics{parallel_reduction}

{\tiny (\url{https://scs.senecac.on.ca/~gpu610/pages/images/parallel_reduction.png})}
\end{center}


\end{frame}



\begin{frame}
\frametitle{GPU computing algorithm constraints}

\begin{center}
\begin{tabular}{ll}
Constraint & Solution \\
\hline
memory coalescence \pause & set up proper data structures \pause \\ \\
only uniform and normal RNGs \pause & step out slice sampler \pause \\ \\
data transfer speed \pause & thinning \pause \\ \\
& return draws for a small subset of parameters \\
& \quad hyperparameters \\
& \quad random set of gene-specific parameters \pause \\ \\
& calculate running sums for \\
& \quad convergence diagnostics \\
& \quad normal-based credible intervals \\
& \quad hypothesis probabilities \\
\hline
\end{tabular}
\end{center}
\end{frame}



\begin{frame}
\frametitle{Convergence diagnostics}
\small

For each parameter $\theta$ over the $M$ iterations of chain $c$, calculate 
\[ 
\ov{\theta}_c= \frac{1}{M}\sum_{m = 1}^M \theta_c^{(m)} 
\qquad\mbox{and}\qquad
\ov{\theta^2}_c = \frac{1}{M} \sum_{m = 1}^M \left(\theta_c^{(m)} \right)^2.
\]
using a numerically stable one-pass (or online) algorithm.

\vspace{0.1in} \pause \pause

Compute  the Gelman-Rubin convergence diagnostic amongst $C$ chains using
\[
\widehat{R} = \sqrt{1 + \frac{1}{M} \left(\frac{B}{W} - 1 \right)}
\] 
where 
\[
B = \frac{M}{C - 1} \sum_{c = 1}^C  \left (\ov{\theta}_c - \ov{\theta} \right )^2,
W = \frac{1}{C} \sum_{c = 1}^C S_c^2,
\]
\[
\ov{\theta} = \frac{1}{C} \sum_{c = 1}^C \ov{\theta}_c,
\mbox{ and }
S_c^2 = \frac{M}{M-1}\left[\ov{\theta^2}_c-\ov{\theta}^2_c \right] \approx \ov{\theta^2}_c-\ov{\theta}^2_c 
%\frac{1}{M - 1} \sum_{m = 1}^M \left (\theta_c^{(m)} - \ov{\theta}_c \right )^2
.
\]

\end{frame}


\begin{frame}
\frametitle{Normal-based credible intervals}

For the collection of parameters $\psi$ and under regularity conditions, we have 
\[ 
p_N(\psi|y_N) \stackrel{d}{\to} N\left(\psi_0, \left[\mathrm{I}_N(\psi_0)\right]^{-1}\right)
\]
as $N\to \infty$ where $\psi_0$ is the true value and $\mathrm{I}_N(\psi_0)$ is the Fisher information. 

\vspace{0.1in} \pause

For any scalar parameter $\theta$, we have 
\[ 
\theta|y \dot\sim N\left(\ov{\theta}, \ov{\theta^2}-\ov{\theta}^2\right)
\]
\pause
and can construct normal-based credible intervals with 
\[ 
\ov{\theta} \pm z_{\alpha/2} \sqrt{\ov{\theta^2}-\ov{\theta}^2}
\]
where $P(Z>z_\alpha)=\alpha$ and $Z$ is a standard normal distribution.
\end{frame}




\begin{frame}
\frametitle{Estimating hypothesis probabilities}

Recall we are interested in estimating probabilities similar to 

\[ \begin{array}{l}
P(\mbox{high parent heterosis for the B73$\times$Mo17 hybrid}|y) \\ \\
\qquad = P\left(\left.2\beta_{g2} + \beta_{g4}>0 \mbox{ and }  2\beta_{g3} + \beta_{g4} > 0\right|y \right) \pause \\ \\
\qquad \approx \frac{1}{M} \sum_{m=1}^M \mathrm{I}\left( 2\beta_{g2}^{(m)} + \beta_{g4}^{(m)}>0\right)\mathrm{I}\left(2\beta_{g3}^{(m)} + \beta_{g4}^{(m)} > 0 \right) 
\end{array} \]

\vspace{0.1in} \pause

We can use the running sums to keep track of this sum. 

\end{frame}



\begin{frame}[fragile]
\frametitle{Implementation}
The computation for this hierarchical count regression model is provided in the following three R packages:

\begin{itemize}
\item {\tt fbseq}: user interface 
\item {\tt fbseqOpenMP}: multithreaded backend
\item {\tt fbseqCUDA}: GPU backend
\end{itemize}

\pause

<<setup,size="tiny">>=
library(fbseq)
data(paschold) # Paschold et. al. (2012) data

paschold@contrasts[[5]]
paschold@contrasts[[6]]
paschold@propositions$`high-parent_B73xMo17`
@

<<dependson="setup",eval=FALSE, size="tiny">>=
configs    = Configs(burnin = 10, iterations = 10, thin = 1) 
chain      = Chain(paschold, configs) 
chain_list = fbseq(chain, backend = "CUDA")
@
\end{frame}




\section{Simulation studies}
\subsection{Credible interval coverage}
\subsection{Heterosis detection}

\section{Real data analysis}

\section{Future work}
\subsection{Alternative hierarchical distributions}
\subsection{Semi-parametric approach}
\subsection{Allele specific expression}



\begin{frame}
\frametitle{References}
\tiny

\begin{itemize}
\item Gelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). \emph{Bayesian analysis}, 1(3), 515--534.
\item Gelman, A., Hill, J., and Yajima, M. (2012). Why we (usually) don't have to worry about multiple comparisons. \emph{Journal of Research on Educational Effectiveness}, 5(2), 189--211.
\item Paschold, A., Jia, Y., Marcon, C., Lund, S., Larson, N.B., Yeh, C.T., Ossowski, S., Lanz, C., Nettleton, D., Schnable, P.S. and Hochholdinger, F., 2012. Complementation contributes to transcriptome complexity in maize (Zea mays L.) hybrids relative to their inbred parents. \emph{Genome researc}h, 22(12), pp.2445--2454.
\end{itemize}

\end{frame}

\end{document}   














